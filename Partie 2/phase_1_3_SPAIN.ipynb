{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperation des donn√©es Espagne WEB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques n√©cessaires\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# √âtape 1: R√©cup√©ration de la page web\n",
    "def get_webpage_content(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la r√©cup√©ration de la page: {e}\")\n",
    "        return None\n",
    "\n",
    "# √âtape 2: Extraction des liens sp√©cifiques\n",
    "def extract_review_links(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Recherche de tous les liens\n",
    "    review_links = []\n",
    "    \n",
    "    # Utilisation d'une expression r√©guli√®re pour trouver les liens sp√©cifiques\n",
    "    pattern = r'https?://[^\\s<>\"]+?/spain/[^\\s<>\"]+?reviews\\.csv'\n",
    "    links = re.findall(pattern, html_content)\n",
    "    \n",
    "    # Nettoie et ajoute les liens valides\n",
    "    for link in links:\n",
    "        if link.endswith('reviews.csv') and 'spain' in link.lower():\n",
    "            review_links.append(link)\n",
    "    \n",
    "    # Supprime les doublons\n",
    "    review_links = list(set(review_links))\n",
    "    return review_links\n",
    "\n",
    "# √âtape 3: Cr√©ation du DataFrame avec informations suppl√©mentaires\n",
    "def create_dataframe(links):\n",
    "    data = []\n",
    "    for link in links:\n",
    "        # Extraction des informations de l'URL\n",
    "        parts = link.split('/')\n",
    "        ville = parts[-4] if len(parts) >= 4 else ''\n",
    "        date = parts[-3] if len(parts) >= 3 else ''\n",
    "        \n",
    "        data.append({\n",
    "            'url': link,\n",
    "            'ville': ville,\n",
    "            'date': date\n",
    "        })\n",
    "    \n",
    "    # Cr√©ation du DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# √âtape 4: Ex√©cution du code\n",
    "def main():\n",
    "    url = \"https://insideairbnb.com/get-the-data/\"\n",
    "    print(\"R√©cup√©ration des donn√©es depuis le site...\")\n",
    "    html_content = get_webpage_content(url)\n",
    "    \n",
    "    if html_content:\n",
    "        review_links = extract_review_links(html_content)\n",
    "        \n",
    "        # Cr√©ation du DataFrame\n",
    "        df = create_dataframe(review_links)\n",
    "        \n",
    "        # Affichage des informations\n",
    "        print(f\"\\nNombre de liens reviews.csv trouv√©s: {len(review_links)}\")\n",
    "        print(\"\\nAper√ßu du DataFrame:\")\n",
    "        print(df)\n",
    "        \n",
    "        return df  # Retourne le DataFrame pour utilisation ult√©rieure\n",
    "\n",
    "# Ex√©cution du programme\n",
    "if __name__ == \"__main__\":\n",
    "    df_results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie DATA LAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import des biblioth√®ques n√©cessaires\n",
    "from azure.identity import ClientSecretCredential, DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Configuration des informations d'authentification\n",
    "# Configuration Key Vault\n",
    "key_vault_url = os.getenv('KEY_VAULT_URL')\n",
    "secret_name = os.getenv('WRITE_SECRET_NAME')\n",
    "\n",
    "# Configuration Azure AD\n",
    "tenant_id = os.getenv('TENANT_ID')\n",
    "client_id = os.getenv('WRITE_CLIENT_ID')\n",
    "\n",
    "# Configuration Storage\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "container_name = os.getenv('CONTAINER_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. R√©cup√©ration du secret depuis Key Vault\n",
    "def get_secret_from_keyvault():\n",
    "    try:\n",
    "        # Utilisation de DefaultAzureCredential pour l'authentification\n",
    "        credential = DefaultAzureCredential()\n",
    "        \n",
    "        # Cr√©ation du client Key Vault\n",
    "        secret_client = SecretClient(vault_url=key_vault_url, credential=credential)\n",
    "        \n",
    "        # R√©cup√©ration du secret\n",
    "        secret = secret_client.get_secret(secret_name)\n",
    "        return secret.value\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la r√©cup√©ration du secret: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Cr√©ation des credentials\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    client_secret = get_secret_from_keyvault()\n",
    "    if client_secret:\n",
    "        return ClientSecretCredential(\n",
    "            tenant_id=tenant_id,\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret\n",
    "        )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fonction pour transf√©rer un seul fichier CSV\n",
    "def transfer_single_csv(url, file_system_client, ville):\n",
    "    try:\n",
    "        # Cr√©ation du nom de fichier de destination\n",
    "        file_name = f\"{ville}_reviews.csv\"\n",
    "        destination_path = f\"airbnb_data/spain/{ville}/{file_name}\"\n",
    "        \n",
    "        print(f\"\\nüì• D√©but du transfert pour {ville}...\")\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        # Cr√©ation du fichier dans le Data Lake\n",
    "        file_client = file_system_client.create_file(destination_path)\n",
    "        \n",
    "        current_position = 0\n",
    "        for chunk in response.iter_content(chunk_size=4*1024*1024):\n",
    "            if chunk:\n",
    "                file_client.append_data(data=chunk, offset=current_position)\n",
    "                current_position += len(chunk)\n",
    "                \n",
    "                if total_size:\n",
    "                    progress = (current_position / total_size) * 100\n",
    "                    print(f\"\\r{ville}: {progress:.2f}% ({current_position/(1024*1024):.2f} Mo)\", end='')\n",
    "        \n",
    "        file_client.flush_data(current_position)\n",
    "        print(f\"\\n‚úÖ {ville} transf√©r√© avec succ√®s!\")\n",
    "        return True, ville, current_position\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur lors du transfert de {ville}: {str(e)}\")\n",
    "        return False, ville, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fonction pour transf√©rer un seul fichier CSV\n",
    "def transfer_single_csv(url, file_system_client, ville):\n",
    "    try:\n",
    "        # Cr√©ation du nom de fichier de destination\n",
    "        file_name = f\"{ville}_reviews.csv\"\n",
    "        destination_path = f\"airbnb_data/spain/{ville}/{file_name}\"\n",
    "        \n",
    "        print(f\"\\nüì• D√©but du transfert pour {ville}...\")\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        # Cr√©ation du fichier dans le Data Lake\n",
    "        file_client = file_system_client.create_file(destination_path)\n",
    "        \n",
    "        current_position = 0\n",
    "        for chunk in response.iter_content(chunk_size=4*1024*1024):\n",
    "            if chunk:\n",
    "                file_client.append_data(data=chunk, offset=current_position)\n",
    "                current_position += len(chunk)\n",
    "                \n",
    "                if total_size:\n",
    "                    progress = (current_position / total_size) * 100\n",
    "                    print(f\"\\r{ville}: {progress:.2f}% ({current_position/(1024*1024):.2f} Mo)\", end='')\n",
    "        \n",
    "        file_client.flush_data(current_position)\n",
    "        print(f\"\\n‚úÖ {ville} transf√©r√© avec succ√®s!\")\n",
    "        return True, ville, current_position\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur lors du transfert de {ville}: {str(e)}\")\n",
    "        return False, ville, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fonction principale pour traiter le DataFrame\n",
    "def process_dataframe_urls(df, max_workers=3):\n",
    "    try:\n",
    "        print(f\"üöÄ D√©marrage du transfert pour {len(df)} fichiers...\")\n",
    "        \n",
    "        # Configuration du client Data Lake\n",
    "        credential = create_credentials()\n",
    "        if not credential:\n",
    "            raise Exception(\"Impossible d'obtenir les credentials\")\n",
    "        \n",
    "        account_url = f\"https://{storage_account_name}.dfs.core.windows.net\"\n",
    "        service_client = DataLakeServiceClient(account_url, credential=credential)\n",
    "        file_system_client = service_client.get_file_system_client(container_name)\n",
    "        \n",
    "        successful_transfers = 0\n",
    "        total_size = 0\n",
    "        \n",
    "        # Traitement parall√®le des fichiers\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_url = {\n",
    "                executor.submit(\n",
    "                    transfer_single_csv,\n",
    "                    row['url'],\n",
    "                    file_system_client,\n",
    "                    row['ville']\n",
    "                ): row['ville']\n",
    "                for _, row in df.iterrows()\n",
    "            }\n",
    "            \n",
    "            for future in as_completed(future_to_url):\n",
    "                success, ville, size = future.result()\n",
    "                if success:\n",
    "                    successful_transfers += 1\n",
    "                    total_size += size\n",
    "        \n",
    "        print(f\"\\nüìä R√©sum√© du transfert:\")\n",
    "        print(f\"- Fichiers transf√©r√©s avec succ√®s: {successful_transfers}/{len(df)}\")\n",
    "        print(f\"- Taille totale transf√©r√©e: {total_size/(1024*1024*1024):.2f} Go\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur g√©n√©rale: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Configuration:\n",
      "- Nombre de fichiers √† traiter: 18\n",
      "- 3 t√©l√©chargements simultan√©s\n",
      "üöÄ D√©marrage du transfert pour 18 fichiers...\n",
      "\n",
      "üì• D√©but du transfert pour girona...\n",
      "\n",
      "üì• D√©but du transfert pour mallorca...\n",
      "\n",
      "üì• D√©but du transfert pour sevilla...\n",
      "\n",
      "‚ùå Erreur lors du transfert de sevilla: 403 Client Error: Forbidden for url: https://data.insideairbnb.com/spain/andaluc%C3%83%C2%ADa/sevilla/2024-06-30/data/reviews.csv\n",
      "\n",
      "üì• D√©but du transfert pour valencia...\n",
      "girona: 100.00% (7.72 Mo)\n",
      "‚úÖ girona transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour madrid...\n",
      "madrid: 100.00% (26.23 Mo))\n",
      "‚úÖ madrid transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour menorca...\n",
      "menorca: 100.00% (21.89 Mo)\n",
      "‚úÖ menorca transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour barcelona...\n",
      "valencia: 100.00% (121.21 Mo)\n",
      "‚úÖ valencia transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour sevilla...\n",
      "\n",
      "‚ùå Erreur lors du transfert de sevilla: 403 Client Error: Forbidden for url: https://data.insideairbnb.com/spain/andaluc%C3%83%C2%ADa/sevilla/2024-06-30/visualisations/reviews.csv\n",
      "\n",
      "üì• D√©but du transfert pour barcelona...\n",
      "barcelona: 100.00% (18.48 Mo)\n",
      "‚úÖ barcelona transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour madrid...\n",
      "mallorca: 100.00% (132.82 Mo)\n",
      "‚úÖ mallorca transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour malaga...\n",
      "madrid: 22.10% (72.00 Mo)\n",
      "‚ùå Erreur lors du transfert de malaga: 403 Client Error: Forbidden for url: https://data.insideairbnb.com/spain/andaluc%C3%83%C2%ADa/malaga/2024-06-30/data/reviews.csv\n",
      "\n",
      "üì• D√©but du transfert pour euskadi...\n",
      "euskadi: 100.00% (6.16 Mo)Mo)\n",
      "‚úÖ euskadi transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour girona...\n",
      "barcelona: 100.00% (278.24 Mo)\n",
      "‚ùå Erreur lors du transfert de barcelona: (InvalidFlushPosition) The uploaded data is not contiguous or the position query parameter value is not equal to the length of the file after appending the uploaded data.\n",
      "RequestId:f73de863-a01f-00d3-432b-46df7d000000\n",
      "Time:2024-12-04T09:07:19.7040301Z\n",
      "Code: InvalidFlushPosition\n",
      "Message: The uploaded data is not contiguous or the position query parameter value is not equal to the length of the file after appending the uploaded data.\n",
      "RequestId:f73de863-a01f-00d3-432b-46df7d000000\n",
      "Time:2024-12-04T09:07:19.7040301Z\n",
      "\n",
      "üì• D√©but du transfert pour valencia...\n",
      "valencia: 100.00% (8.64 Mo)\n",
      "‚úÖ valencia transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour malaga...\n",
      "madrid: 58.93% (192.00 Mo)\n",
      "‚ùå Erreur lors du transfert de malaga: 403 Client Error: Forbidden for url: https://data.insideairbnb.com/spain/andaluc%C3%83%C2%ADa/malaga/2024-06-30/visualisations/reviews.csv\n",
      "\n",
      "üì• D√©but du transfert pour menorca...\n",
      "menorca: 100.00% (1.40 Mo)\n",
      "‚úÖ menorca transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour mallorca...\n",
      "mallorca: 100.00% (7.79 Mo)\n",
      "‚úÖ mallorca transf√©r√© avec succ√®s!\n",
      "\n",
      "üì• D√©but du transfert pour euskadi...\n",
      "girona: 100.00% (105.95 Mo)\n",
      "‚úÖ girona transf√©r√© avec succ√®s!\n",
      "euskadi: 100.00% (81.88 Mo)\n",
      "‚úÖ euskadi transf√©r√© avec succ√®s!\n",
      "madrid: 100.00% (325.81 Mo)\n",
      "‚úÖ madrid transf√©r√© avec succ√®s!\n",
      "\n",
      "üìä R√©sum√© du transfert:\n",
      "- Fichiers transf√©r√©s avec succ√®s: 13/18\n",
      "- Taille totale transf√©r√©e: 0.85 Go\n"
     ]
    }
   ],
   "source": [
    "# 7. Utilisation du code\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    MAX_WORKERS = 3  # Nombre de t√©l√©chargements simultan√©s\n",
    "    \n",
    "    print(\"üéØ Configuration:\")\n",
    "    print(f\"- Nombre de fichiers √† traiter: {len(df_results)}\")\n",
    "    print(f\"- {MAX_WORKERS} t√©l√©chargements simultan√©s\")\n",
    "    \n",
    "    # Ex√©cution du transfert\n",
    "    process_dataframe_urls(df_results, MAX_WORKERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
