
# Projet Azure Data Lake Gen2 - S√©curit√© et Configuration

## Description
Ce projet est con√ßu pour mettre en pratique la s√©curisation et la configuration d'Azure Data Lake Storage Gen2. Il comprend diff√©rentes phases d'impl√©mentation, de la veille technologique √† la mise en place d'un syst√®me de monitoring, en passant par l'ingestion s√©curis√©e des donn√©es.

## Pr√©requis
- Python 3.x
- Un compte Azure avec acc√®s aux services suivants :
  - Azure Data Lake Storage Gen2
  - Azure Key Vault
  - Azure Databricks
- Variables d'environnement configur√©es (voir section Configuration)

## Installation
1. Cloner le repository
```bash
git clone [URL_DU_REPO]
```

2. Cr√©er un environnement virtuel
```bash
python -m venv env
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Installer les d√©pendances
```bash
pip install -r requirements.txt
```

## Structure du Projet
```
‚îú‚îÄ‚îÄ Partie 1 Veille_doc/
‚îÇ   ‚îî‚îÄ‚îÄ Documentation et veille technologique (.md)
‚îú‚îÄ‚îÄ Partie 2/
‚îÇ   ‚îú‚îÄ‚îÄ DATA/
‚îÇ   ‚îú‚îÄ‚îÄ Documentation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LOG/ --> les logs en .json du data lake   ## (non disponible dans le .gitigonre) ##
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ blob_screen/ --> dossier avec screen du blog 
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Screen/ --> dossier avec screen des SP , des logs .json , liste des RG pour tout le projet ,
‚îÇ   ‚îú‚îÄ‚îÄ phase_1_1_super_user.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ phase_1_2_Read.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ phase_1_3_SPAIN.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ phase_2_Parquet.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ Explication approche globale SP .md  
‚îî‚îÄ‚îÄ Partie 3/
    ‚îî‚îÄ‚îÄ Screenshots Databricks/
```

## Configuration
Cr√©er un fichier `.env` √† la racine du projet avec les variables suivantes :
```
KEY_VAULT_URL=xxxxxxxxxxxxxxxxxxxx
WRITE_SECRET_NAME=xxxxxxxxxxxxxxxxxxxx
WRITE_CLIENT_ID=xxxxxxxxxxxxxxxxxxxx
READ_SECRET_NAME=xxxxxxxxxxxxxxxxxxxx
READ_CLIENT_ID=xxxxxxxxxxxxxxxxxxxx
TENANT_ID=xxxxxxxxxxxxxxxxxxxx
STORAGE_ACCOUNT_NAME=xxxxxxxxxxxxxxxxxxxx
CONTAINER_NAME=xxxxxxxxxxxxxxxxxxxx
```

## Description des Parties

### Partie 1 : Veille sur les Syst√®mes de S√©curit√©
Documentation et recherche sur les meilleures pratiques de s√©curit√© pour Azure Data Lake.

### Partie 2 : Cr√©ation et Ingestion S√©curis√©e
- Configuration des acc√®s via Azure Key Vault
- Impl√©mentation de diff√©rents niveaux d'acc√®s
- Gestion des permissions granulaires
- Conversion et stockage en format Parquet
- Dans `Documentation` la journalisation des information sont cacher par le `.gitignore` + 3 screen shot

### Partie 3 : Configuration d'Azure Databricks
Screenshots et documentation de la configuration Databricks (Code non inclus pour des raisons de s√©curit√©)

### Partie 4 : Monitoring et Alertes
Mise en place du syst√®me de surveillance et configuration des alertes

### Partie 5 : Bonus
Options disponibles :
- Ingestion Avanc√©e (niveau 2)
- Exploration des Donn√©es avec Spark
- R√©vocation des Acc√®s en Cas d'Incident
- Inspection du Pricing
- Utilisation de Terraform

## S√©curit√©
Les informations sensibles sont g√©r√©es via Azure Key Vault. Les credentials ne doivent jamais √™tre expos√©s dans le code.

---








## Copie du PROJET üìö voir [PDF "Data_Lake_partie_2__ingestion_avance_monitoring_et_scurit.pdf"](./PDF_Data_Lake_partie_2__ingestion_avance_monitoring_et_scurit.pdf) üîç




## Copie du PROJET  voir PDF "Data_Lake_partie_2__ingestion_avance_monitoring_et_scurit.pdf"

